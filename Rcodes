## Bootstrap
```{r }

class=c(141,153,162,178,155,167,139,132,146,148,165,167,171,145,144,165,155,134,131,145,148,137)
n=length(class)
N=1000000
stat = numeric(N)

for (i in 1:N) {
  #bootstrap sample counterparts to observed samples are denoted wiht "B"
  classB= sample(class, n, replace=T)
  stat[i] = var(classB)
}

boxplot(stat)
summary(stat)
```

## cross validation
```{r}
library(ISLR)
library(boot)
set.seed(17)

cv.error.10=rep(0,10)

for (i in 1:10) {
  glm.fit=glm(mpg~poly(horsepower,i),data = Auto)
  cv.error.10[i]=cv.glm(Auto,glm.fit,K=10)$delta[1] 
  # K=10 folders validation, cv.glm to produce cross validation result, cv.glm provides two columns: one for non-biased corrective value one for biased. And using 1 for non-biased. 
}
cv.error.10
plot(cv.error.10) #  by checking, go ahead with a polynomial model with degree of two


```
